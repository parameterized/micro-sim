{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b046de7b-f968-4dbd-84b3-06a1a3827e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad52670-38ee-4cda-a51d-45a79ba7e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['image.cmap'] = 'binary'\n",
    "\n",
    "def display_video(path, loop=True):\n",
    "    mp4 = open(path, 'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "    return display.HTML(f'''<video src=\"{\n",
    "        data_url}\" controls=true autoplay=true {\n",
    "        \"loop=true \" if loop else \"\"}/>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7c0a93-34ca-4dc0-b356-eb81f83b9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'datasets/jams-germs'\n",
    "vid_fnames = os.listdir(f'{dataset_path}/raw-videos')\n",
    "resize = transforms.Compose([transforms.ToTensor(),\n",
    "    transforms.Resize(512, transforms.InterpolationMode.BICUBIC)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7de800-8cdf-4c0c-8a64-3ff86bd3eff9",
   "metadata": {},
   "source": [
    "## Test batch sampling time from video files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814bfef3-e0a2-4277-b478-873bfe2ff83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.43s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "batch_frames = 16\n",
    "batch = []\n",
    "time_start = time.time()\n",
    "for i in range(batch_size):\n",
    "    vid_id = np.random.randint(len(vid_fnames))\n",
    "    vid_fname = vid_fnames[vid_id]\n",
    "    vid_path = f'{dataset_path}/raw-videos/{vid_fname}'\n",
    "    \n",
    "    vidcap = cv2.VideoCapture(vid_path)\n",
    "    frame_count = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    start_frame = np.random.randint(frame_count - batch_frames + 1)\n",
    "    \n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    batch.append([])\n",
    "    for _ in range(batch_frames):\n",
    "        success, img = vidcap.read()\n",
    "        img = resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        batch[-1].append(img)\n",
    "\n",
    "print(f'{(time.time() - time_start):.2f}s')\n",
    "# 18s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2b40e-1386-469a-ba56-49806541949a",
   "metadata": {},
   "source": [
    "## Convert first video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1db7c2-a79b-436c-bc92-a418b858d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00s\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "for vid_fname in vid_fnames[:1]:\n",
    "    break\n",
    "    \n",
    "    title = '-'.join(vid_fname.split('-')[:-1])\n",
    "    vid_path = f'{dataset_path}/raw-videos/{vid_fname}'\n",
    "    frames_path = f'{dataset_path}/frames/{title}'\n",
    "    os.makedirs(frames_path, exist_ok=True)\n",
    "    \n",
    "    vidcap = cv2.VideoCapture(vid_path)\n",
    "    frame_id = 0\n",
    "    while True:\n",
    "        success, img = vidcap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        img = resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        torchvision.utils.save_image(\n",
    "            img, f'{frames_path}/{frame_id}.jpg')\n",
    "        frame_id += 1\n",
    "\n",
    "print(f'{(time.time() - time_start):.2f}s')\n",
    "# takes about the same time as video length\n",
    "# 80mb -> 120mb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e049b5a0-e727-4b20-9edc-84ce83d09b10",
   "metadata": {},
   "source": [
    "## Test batch sampling time from frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48543517-0caf-4220-b849-124e0f2d14dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.48s\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "batch_frames = 16\n",
    "batch = []\n",
    "\n",
    "frames_path = 'datasets/jams-germs/frames/Earthworm Under Microscope'\n",
    "frame_count = len(os.listdir(frames_path))\n",
    "to_tensor = transforms.PILToTensor()\n",
    "\n",
    "time_start = time.time()\n",
    "for i in range(batch_size):    \n",
    "    start_frame = np.random.randint(frame_count - batch_frames + 1)\n",
    "    batch.append([])\n",
    "    for j in range(batch_frames):\n",
    "        img = Image.open(f'{frames_path}/{start_frame + j}.jpg')\n",
    "        batch[-1].append(to_tensor(img))\n",
    "\n",
    "print(f'{(time.time() - time_start):.2f}s')\n",
    "# 3s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
